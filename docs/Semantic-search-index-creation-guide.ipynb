{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic search index creation \n",
    "\n",
    "### *Guide*\n",
    "\n",
    "Anton Antonov    \n",
    "September 2024  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to create an LLM-computed vector database over the paragraphs of relative large text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "use Data::Importers;\n",
    "use LLM::Configurations;\n",
    "use LLM::Functions;\n",
    "use XDG::BaseDirectory :terms;\n",
    "\n",
    "use LLM::RetrievalAugmentedGeneration;\n",
    "use LLM::RetrievalAugmentedGeneration::VectorDatabase;\n",
    "\n",
    "use Data::Reshapers;\n",
    "use Data::Summarizers;\n",
    "use Math::Nearest;\n",
    "use Math::DistanceFunctions;\n",
    "use Statistics::OutlierIdentifiers;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Ingest text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingest the transcript of the (3.5 hours) discussion [CWv1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(chars => 245233 words => 36863 lines => 7107)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $url = 'https://podscripts.co/podcasts/modern-wisdom/833-eric-weinstein-are-we-on-the-brink-of-a-revolution';\n",
    "my $txtEN = data-import($url, 'plaintext');\n",
    "\n",
    "text-stats($txtEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the \"proper transcript\" part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(chars => 242067 words => 36490 lines => 7048)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $txtEN2 = $txtEN.substr($txtEN.index('Starting point is 00:00:00'));\n",
    "text-stats($txtEN2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into paragraphs and make the paragraphs compact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my @paragraphs = $txtEN2.split(/ 'Starting point is' \\h+ [\\d ** 2]+ % ':' /):g;\n",
    "@paragraphs .= map({ $_.subst(/\\n+/, \"\\n\"):g});\n",
    "@paragraphs.elems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a sample of the paragraphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ul><li> \n",
       "                                         and financial consequences of reputation harm,\n",
       "but often in media, that&#39;s not what kills you.\n",
       "Instead, it&#39;s your own unforced errors\n",
       "in response to the criticism.\n",
       "Some people change their messaging to avoid the blowback,\n",
       "like a wide receiver shying from necessary contact over the middle.\n",
       "Some disagreeable personalities get their backs up and over-correct.\n",
       "Their content starts to match the fevered pitch of their most aggressive detractors.\n",
       "                                            </li><li> \n",
       "                                         It&#39;s theoretical retconning.\n",
       "Yeah.\n",
       "And, uh, you know, there&#39;s this beautiful offering that Hector makes to Achilles.\n",
       "We will give each other the honor of a proper burial.\n",
       "Achilles is an interested.\n",
       "Let&#39;s do this thing. What does that mean?\n",
       "Well hopefully somebody will come up with some money to hold a conference to get these\n",
       "people in the same room with the people they&#39;ve tormented, whose careers they&#39;ve ended, whose\n",
       "                                            </li><li> \n",
       "                                         But then if you were to see Douglas Murray\n",
       "and Malcolm Gladwell on stage together,\n",
       "or Ben Shapiro and anybody,\n",
       "and you go, they&#39;re able to be disagreeable so seamlessly.\n",
       "For me to get even 5% of the way there,\n",
       "I need to do the equivalent of a one rep max\n",
       "to ask Abigail Shrier about CBT.\n",
       "And that&#39;s for me just an obvious area\n",
       "                                            </li><li> \n",
       "                                         was how they opened up that Pang-Burn debate.\n",
       "So I think he got it.\n",
       "I think you can hear on something called Faith in Reason\n",
       "where Sam asks me to clarify what that means.\n",
       "And it wasn&#39;t original to me,\n",
       "but it&#39;s a really important concept.\n",
       "It&#39;s very cool.\n",
       "And...\n",
       "                                            </li></ul>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% html\n",
    "@paragraphs.pick(4) ==> to-html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Make vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an empty vector database object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorDatabase(:id(\"266b20ca-d917-4ac0-9b0a-7c420625666c\"), :name(\"No833\"), :elements(0), :sources(0))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $vdbObj = LLM::RetrievalAugmentedGeneration::VectorDatabase.new(name => 'No833');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an LLM access specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $conf = llm-configuration(\"ChatGPT\", model => 'text-embedding-002');\n",
    "#my $conf = llm-configuration(\"Gemini\");\n",
    "\n",
    "$conf.Hash.elems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the semantic index for the vector database object (an profile it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to make the semantic search index: 235.6492823 seconds.\n"
     ]
    }
   ],
   "source": [
    "my $tstart = now;\n",
    "$vdbObj.create-semantic-search-index(@paragraphs, method => 'by-max-tokens', max-tokens => 2048, e => $conf):embed;\n",
    "my $tend = now;\n",
    "say \"Time to make the semantic search index: {$tend - $tstart} seconds.\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the vector database object is exported in a sub-directory of [`$XDG_DATA_HOME`](https://specifications.freedesktop.org/basedir-spec/latest/index.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The sub-directory\n",
    "my $dirname = data-home.Str ~ '/raku/LLM/SemanticSearchIndex';\n",
    "\n",
    "# The exported vector database base file name\n",
    "my $basename = \"SemSe-{$vdbObj.id}.json\";\n",
    "\n",
    "# Corresponding IO:Path object\n",
    "my $file = IO::Path.new(:$dirname, :$basename);\n",
    "\n",
    "# Check for existence\n",
    "$file.f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The export path is saved in the vector database object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "$file.Str eq $vdbObj.location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a sample of the text chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ul><li><table border=\"1\"><tr><th>290.0</th><td>of abundance of women and the guest then goes, ah. So Joe doesn&#39;t make a conversation feel like an interview because he answers statements with statements. If you actually listen, a lot of the time, Joe doesn&#39;t ask that many questions in his podcast. He&#39;s not a big question asker when compared with most other podcasters. He makes statements.</td></tr></table></li><li><table border=\"1\"><tr><th>382.0</th><td>And I have an enormous number of gay friends. It&#39;s not some of my best friends are gay. It&#39;s like way too many of them are gay. So I spent a lot of time in, in gay space. And what I&#39;ve learned from that is that you can go about 85% of the distance talking about relationships, sex in the abstract, hopes, dreams for the future, attraction. And then the last 15% is really different. And I don&#39;t want to be in your business at all. And it&#39;s constructed that way because we freak each other out. We don&#39;t really want the specifics of the details beyond a certain point. And I think that that last 15% can&#39;t be shared between straights and gays. We can go 85%</td></tr></table></li><li><table border=\"1\"><tr><th>420.0</th><td>And the Kennedy Shanahan ticket is sophisticated in realizing that campaigning could be something different. It&#39;s trying to figure out what should campaigning be. But it&#39;s crazy to be an all day session trying to figure out how to save the labor market from AI. And I also want to want to say something about JD Vance without naming names. And I hope JD doesn&#39;t get angry at me for this one. JD invited me out years ago to Ohio</td></tr></table></li><li><table border=\"1\"><tr><th>430.0</th><td>Nicole Shanahan and Bobby Kennedy are 100% sincere no matter how they&#39;re campaigning or what you&#39;re upset about in their off moments. And I&#39;ve been with all of them. These people deeply care about the shit out of luck. They&#39;re, they&#39;re interested in taking on real power. I don&#39;t know Trump. I mean, look, you can tell it&#39;s not, there&#39;s no allegiance. I&#39;ve, I can&#39;t imagine voting for Trump.</td></tr></table></li></ul>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% html\n",
    "$vdbObj.text-chunks.pairs.pick(4).sort(*.key) ==> to-html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show dimensions and data type of the obtained vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions : (441 1536)\n",
      "data type  : Assoc(Atom((Str)), Vector(Atom((Numeric)), 1536), 441)\n"
     ]
    }
   ],
   "source": [
    "say \"dimensions : \", $vdbObj.database.&dimensions;\n",
    "say \"data type  : \", deduce-type($vdbObj.database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles\n",
    "\n",
    "[AA1] Anton Antonov, \n",
    "[\"Outlier detection in a list of numbers\"](https://rakuforprediction.wordpress.com/2022/05/29/outlier-detection-in-a-list-of-numbers/),\n",
    "(2022),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "\n",
    "[AAp1] Anton Antonov,\n",
    "[WWW::OpenAI Raku package](https://github.com/antononcube/Raku-WWW-OpenAI),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp2] Anton Antonov,\n",
    "[WWW::PaLM Raku package](https://github.com/antononcube/Raku-WWW-PaLM),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp3] Anton Antonov,\n",
    "[LLM::Functions Raku package](https://github.com/antononcube/Raku-LLM-Functions),\n",
    "(2023-2024),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp4] Anton Antonov,\n",
    "[LLM::Prompts Raku package](https://github.com/antononcube/Raku-LLM-Prompts),\n",
    "(2023-2024),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp5] Anton Antonov,\n",
    "[ML::FindTextualAnswer Raku package](https://github.com/antononcube/Raku-ML-FindTextualAnswer),\n",
    "(2023-2024),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp6] Anton Antonov,\n",
    "[Math::Nearest Raku package](https://github.com/antononcube/Raku-Math-Nearest),\n",
    "(2024),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp7] Anton Antonov,\n",
    "[Math::DistanceFunctions Raku package](https://github.com/antononcube/Raku-Math-DistanceFunctions),\n",
    "(2024),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp8] Anton Antonov,\n",
    "[Statistics::OutlierIdentifiers Raku package](https://github.com/antononcube/Raku-Statistics-OutlierIdentifiers),\n",
    "(2022),\n",
    "[GitHub/antononcube](https://github.com/antononcube)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Videos\n",
    "\n",
    "[CWv1] Chris Williamson,\n",
    "[\"Eric Weinstein - Are We On The Brink Of A Revolution? (4K)\"](https://www.youtube.com/watch?v=PYRYXhU4kxM),\n",
    "(2024),\n",
    "[YouTube/@ChrisWillx](https://www.youtube.com/@ChrisWillx).   \n",
    "([transcript](https://podscripts.co/podcasts/modern-wisdom/833-eric-weinstein-are-we-on-the-brink-of-a-revolution).)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RakuChatbook",
   "language": "raku",
   "name": "raku"
  },
  "language_info": {
   "file_extension": ".raku",
   "mimetype": "text/x-raku",
   "name": "raku",
   "version": "6.d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
